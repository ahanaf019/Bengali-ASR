{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_DEVICE_MIN_SYS_MEMORY_IN_MB'] = '128' \n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User is already logged in.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login(new_session=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'bn'\n",
    "model_str = 'whisper-tiny'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahanaf/Torch/torch2_2/lib/python3.11/site-packages/datasets/load.py:2516: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n",
      "/home/ahanaf/Torch/torch2_2/lib/python3.11/site-packages/datasets/load.py:1461: FutureWarning: The repository for mozilla-foundation/common_voice_11_0 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mozilla-foundation/common_voice_11_0\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/ahanaf/Torch/torch2_2/lib/python3.11/site-packages/datasets/load.py:2516: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n",
      "/home/ahanaf/Torch/torch2_2/lib/python3.11/site-packages/datasets/load.py:1461: FutureWarning: The repository for mozilla-foundation/common_voice_11_0 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mozilla-foundation/common_voice_11_0\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IterableDatasetDict({\n",
      "    train: IterableDataset({\n",
      "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
      "        n_shards: 1\n",
      "    })\n",
      "    validation: IterableDataset({\n",
      "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
      "        n_shards: 1\n",
      "    })\n",
      "    test: IterableDataset({\n",
      "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
      "        n_shards: 1\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, IterableDatasetDict, DatasetDict\n",
    "\n",
    "common_voice = IterableDatasetDict()\n",
    "\n",
    "\n",
    "common_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", language, split=\"train\", use_auth_token=True, streaming=True)\n",
    "common_voice[\"validation\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", language, split=\"validation\", use_auth_token=True, streaming=True)\n",
    "common_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", language, split=\"test\", use_auth_token=True, streaming=True)\n",
    "\n",
    "print(common_voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
       "    n_shards: 1\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_voice[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice = common_voice.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperFeatureExtractor\n",
    "from transformers import WhisperTokenizer\n",
    "from transformers import WhisperProcessor\n",
    "\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(f\"openai/{model_str}\")\n",
    "tokenizer = WhisperTokenizer.from_pretrained(f\"openai/{model_str}\", language='Bengali', task=\"transcribe\")\n",
    "processor = WhisperProcessor.from_pretrained(f\"openai/{model_str}\", language=\"Bengali\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in common_voice['train']:\n",
    "#     arr = x['audio']['array']\n",
    "#     data_sample = x\n",
    "#     print(arr.min(), arr.max())\n",
    "#     break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_str = data_sample[\"sentence\"]\n",
    "# labels = tokenizer(input_str).input_ids\n",
    "# decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\n",
    "# decoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "# print(f\"Input:                 {input_str}\")\n",
    "# print(f\"Decoded w/ special:    {decoded_with_special}\")\n",
    "# print(f\"Decoded w/out special: {decoded_str}\")\n",
    "# print(f\"Are equal:             {input_str == decoded_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IterableDataset({\n",
      "    features: ['audio', 'sentence'],\n",
      "    n_shards: 1\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(common_voice[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in common_voice[\"train\"]:\n",
    "#     print(x)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    # print(batch)\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array \n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids \n",
    "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_common_voice = common_voice.map(prepare_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: Unknown,\n",
       "    n_shards: 1\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_common_voice['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in mapped_common_voice['train']:\n",
    "#     print(x)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(f\"openai/{model_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generation_config.language = \"bengali\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "\n",
    "model.generation_config.forced_decoder_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"./{model_str}-{language}2\",  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    max_steps=14000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=16,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=400,\n",
    "    save_steps=2000,\n",
    "    eval_steps=2000,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    # push_to_hub=True,\n",
    "    dataloader_prefetch_factor=128,\n",
    "    dataloader_num_workers=16,\n",
    "    auto_find_batch_size=True,\n",
    "    # hub_private_repo=\n",
    "    resume_from_checkpoint=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahanaf/Torch/torch2_2/lib/python3.11/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=mapped_common_voice[\"train\"],\n",
    "    eval_dataset=mapped_common_voice[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82ca9b983304e9f888166f8e3892bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Too many dataloader workers: 16 (max is dataset.n_shards=1). Stopping 15 dataloader workers.\n",
      "Reading metadata...: 16777it [00:03, 5571.44it/s]\n",
      "/home/ahanaf/Torch/torch2_2/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1569, 'grad_norm': 87.94834899902344, 'learning_rate': 4.2000000000000006e-07, 'epoch': 0.0}\n",
      "{'loss': 2.7364, 'grad_norm': 28.024662017822266, 'learning_rate': 9.200000000000001e-07, 'epoch': 0.0}\n",
      "{'loss': 2.269, 'grad_norm': 13.538902282714844, 'learning_rate': 1.42e-06, 'epoch': 0.01}\n",
      "{'loss': 1.9094, 'grad_norm': 12.83574104309082, 'learning_rate': 1.9200000000000003e-06, 'epoch': 0.01}\n",
      "{'loss': 1.67, 'grad_norm': 8.416497230529785, 'learning_rate': 2.42e-06, 'epoch': 0.01}\n",
      "{'loss': 1.5258, 'grad_norm': 13.104721069335938, 'learning_rate': 2.92e-06, 'epoch': 0.01}\n",
      "{'loss': 1.4346, 'grad_norm': 11.164371490478516, 'learning_rate': 3.4200000000000007e-06, 'epoch': 0.01}\n",
      "{'loss': 1.3795, 'grad_norm': 8.804588317871094, 'learning_rate': 3.920000000000001e-06, 'epoch': 0.01}\n",
      "{'loss': 1.3405, 'grad_norm': 8.74685001373291, 'learning_rate': 4.42e-06, 'epoch': 0.02}\n",
      "{'loss': 1.3196, 'grad_norm': 10.954477310180664, 'learning_rate': 4.92e-06, 'epoch': 0.02}\n",
      "{'loss': 1.2939, 'grad_norm': 11.494945526123047, 'learning_rate': 5.420000000000001e-06, 'epoch': 0.02}\n",
      "{'loss': 1.2791, 'grad_norm': 12.170690536499023, 'learning_rate': 5.92e-06, 'epoch': 0.02}\n",
      "{'loss': 1.2701, 'grad_norm': 10.518072128295898, 'learning_rate': 6.42e-06, 'epoch': 0.02}\n",
      "{'loss': 1.2458, 'grad_norm': 14.733673095703125, 'learning_rate': 6.92e-06, 'epoch': 0.03}\n",
      "{'loss': 1.232, 'grad_norm': 12.878279685974121, 'learning_rate': 7.420000000000001e-06, 'epoch': 0.03}\n",
      "{'loss': 1.2165, 'grad_norm': 15.114890098571777, 'learning_rate': 7.92e-06, 'epoch': 0.03}\n",
      "{'loss': 1.1957, 'grad_norm': 14.384353637695312, 'learning_rate': 8.42e-06, 'epoch': 0.03}\n",
      "{'loss': 1.1866, 'grad_norm': 11.675699234008789, 'learning_rate': 8.920000000000001e-06, 'epoch': 0.03}\n",
      "{'loss': 1.1529, 'grad_norm': 15.048943519592285, 'learning_rate': 9.42e-06, 'epoch': 0.03}\n",
      "{'loss': 1.1368, 'grad_norm': 14.537004470825195, 'learning_rate': 9.920000000000002e-06, 'epoch': 0.04}\n",
      "{'loss': 1.0911, 'grad_norm': 19.92896842956543, 'learning_rate': 9.984444444444446e-06, 'epoch': 0.04}\n",
      "{'loss': 0.9922, 'grad_norm': 13.822680473327637, 'learning_rate': 9.965925925925927e-06, 'epoch': 0.04}\n",
      "{'loss': 0.8678, 'grad_norm': 16.416059494018555, 'learning_rate': 9.947407407407408e-06, 'epoch': 0.04}\n",
      "{'loss': 0.7358, 'grad_norm': 13.826170921325684, 'learning_rate': 9.92888888888889e-06, 'epoch': 0.04}\n",
      "{'loss': 0.6222, 'grad_norm': 11.643628120422363, 'learning_rate': 9.910370370370371e-06, 'epoch': 0.04}\n",
      "{'loss': 0.6107, 'grad_norm': 15.832002639770508, 'learning_rate': 9.891851851851852e-06, 'epoch': 0.05}\n",
      "{'loss': 0.5702, 'grad_norm': 12.02670955657959, 'learning_rate': 9.873333333333334e-06, 'epoch': 0.05}\n",
      "{'loss': 0.55, 'grad_norm': 12.018804550170898, 'learning_rate': 9.854814814814817e-06, 'epoch': 0.05}\n",
      "{'loss': 0.4619, 'grad_norm': 9.372665405273438, 'learning_rate': 9.836296296296297e-06, 'epoch': 0.05}\n",
      "{'loss': 0.4275, 'grad_norm': 9.76371955871582, 'learning_rate': 9.817777777777778e-06, 'epoch': 0.05}\n",
      "{'loss': 0.4221, 'grad_norm': 12.072061538696289, 'learning_rate': 9.79925925925926e-06, 'epoch': 0.06}\n",
      "{'loss': 0.3821, 'grad_norm': 9.775486946105957, 'learning_rate': 9.780740740740742e-06, 'epoch': 0.06}\n",
      "{'loss': 0.3798, 'grad_norm': 11.429499626159668, 'learning_rate': 9.762222222222222e-06, 'epoch': 0.06}\n",
      "{'loss': 0.3855, 'grad_norm': 9.987638473510742, 'learning_rate': 9.743703703703705e-06, 'epoch': 0.06}\n",
      "{'loss': 0.3889, 'grad_norm': 7.541277885437012, 'learning_rate': 9.725185185185186e-06, 'epoch': 0.06}\n",
      "{'loss': 0.3533, 'grad_norm': 9.328348159790039, 'learning_rate': 9.706666666666668e-06, 'epoch': 0.06}\n",
      "{'loss': 0.3377, 'grad_norm': 7.536687850952148, 'learning_rate': 9.688148148148149e-06, 'epoch': 0.07}\n",
      "{'loss': 0.3121, 'grad_norm': 6.404638290405273, 'learning_rate': 9.66962962962963e-06, 'epoch': 0.07}\n",
      "{'loss': 0.3766, 'grad_norm': 9.091204643249512, 'learning_rate': 9.651111111111112e-06, 'epoch': 0.07}\n",
      "{'loss': 0.3168, 'grad_norm': 8.922205924987793, 'learning_rate': 9.632592592592593e-06, 'epoch': 0.07}\n",
      "{'loss': 0.3554, 'grad_norm': 9.284536361694336, 'learning_rate': 9.614074074074075e-06, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Too many dataloader workers: 16 (max is dataset.n_shards=1). Stopping 15 dataloader workers.\n",
      "Reading metadata...: 16777it [00:03, 4805.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3963, 'grad_norm': 7.380018711090088, 'learning_rate': 9.595555555555556e-06, 'epoch': 1.0}\n",
      "{'loss': 0.3506, 'grad_norm': 6.660755157470703, 'learning_rate': 9.577037037037039e-06, 'epoch': 1.0}\n",
      "{'loss': 0.3492, 'grad_norm': 8.48245620727539, 'learning_rate': 9.55851851851852e-06, 'epoch': 1.0}\n",
      "{'loss': 0.3446, 'grad_norm': 9.087663650512695, 'learning_rate': 9.54e-06, 'epoch': 1.01}\n",
      "{'loss': 0.3484, 'grad_norm': 8.031760215759277, 'learning_rate': 9.521481481481483e-06, 'epoch': 1.01}\n",
      "{'loss': 0.3368, 'grad_norm': 6.4939985275268555, 'learning_rate': 9.502962962962963e-06, 'epoch': 1.01}\n",
      "{'loss': 0.3408, 'grad_norm': 7.226240634918213, 'learning_rate': 9.484444444444444e-06, 'epoch': 1.01}\n",
      "{'loss': 0.3172, 'grad_norm': 8.998685836791992, 'learning_rate': 9.465925925925927e-06, 'epoch': 1.01}\n",
      "{'loss': 0.3321, 'grad_norm': 7.751436233520508, 'learning_rate': 9.447407407407409e-06, 'epoch': 1.01}\n",
      "{'loss': 0.3152, 'grad_norm': 10.260729789733887, 'learning_rate': 9.42888888888889e-06, 'epoch': 1.02}\n",
      "{'loss': 0.2959, 'grad_norm': 5.978626251220703, 'learning_rate': 9.41037037037037e-06, 'epoch': 1.02}\n",
      "{'loss': 0.3079, 'grad_norm': 6.1417555809021, 'learning_rate': 9.391851851851853e-06, 'epoch': 1.02}\n",
      "{'loss': 0.3029, 'grad_norm': 6.099305152893066, 'learning_rate': 9.373333333333334e-06, 'epoch': 1.02}\n",
      "{'loss': 0.313, 'grad_norm': 9.339313507080078, 'learning_rate': 9.354814814814815e-06, 'epoch': 1.02}\n",
      "{'loss': 0.3091, 'grad_norm': 9.009910583496094, 'learning_rate': 9.336296296296297e-06, 'epoch': 1.03}\n",
      "{'loss': 0.2909, 'grad_norm': 8.876632690429688, 'learning_rate': 9.31777777777778e-06, 'epoch': 1.03}\n",
      "{'loss': 0.2837, 'grad_norm': 9.112824440002441, 'learning_rate': 9.29925925925926e-06, 'epoch': 1.03}\n",
      "{'loss': 0.2792, 'grad_norm': 8.535097122192383, 'learning_rate': 9.280740740740741e-06, 'epoch': 1.03}\n",
      "{'loss': 0.283, 'grad_norm': 6.122712135314941, 'learning_rate': 9.262222222222222e-06, 'epoch': 1.03}\n",
      "{'loss': 0.2959, 'grad_norm': 6.309470176696777, 'learning_rate': 9.243703703703704e-06, 'epoch': 1.03}\n",
      "{'loss': 0.2714, 'grad_norm': 7.559195041656494, 'learning_rate': 9.225185185185185e-06, 'epoch': 1.04}\n",
      "{'loss': 0.2803, 'grad_norm': 7.2360405921936035, 'learning_rate': 9.206666666666668e-06, 'epoch': 1.04}\n",
      "{'loss': 0.2766, 'grad_norm': 6.7072062492370605, 'learning_rate': 9.18814814814815e-06, 'epoch': 1.04}\n",
      "{'loss': 0.2767, 'grad_norm': 7.071789264678955, 'learning_rate': 9.169629629629631e-06, 'epoch': 1.04}\n",
      "{'loss': 0.2609, 'grad_norm': 6.4297356605529785, 'learning_rate': 9.151111111111112e-06, 'epoch': 1.04}\n",
      "{'loss': 0.2392, 'grad_norm': 5.294396877288818, 'learning_rate': 9.132592592592593e-06, 'epoch': 1.04}\n",
      "{'loss': 0.2939, 'grad_norm': 6.253506660461426, 'learning_rate': 9.114074074074075e-06, 'epoch': 1.05}\n",
      "{'loss': 0.2755, 'grad_norm': 9.117965698242188, 'learning_rate': 9.095555555555556e-06, 'epoch': 1.05}\n",
      "{'loss': 0.2982, 'grad_norm': 5.803741931915283, 'learning_rate': 9.077037037037038e-06, 'epoch': 1.05}\n",
      "{'loss': 0.2378, 'grad_norm': 6.434596538543701, 'learning_rate': 9.058518518518519e-06, 'epoch': 1.05}\n",
      "{'loss': 0.2236, 'grad_norm': 7.657376766204834, 'learning_rate': 9.040000000000002e-06, 'epoch': 1.05}\n",
      "{'loss': 0.2241, 'grad_norm': 3.866649866104126, 'learning_rate': 9.021481481481482e-06, 'epoch': 1.06}\n",
      "{'loss': 0.2119, 'grad_norm': 5.853278160095215, 'learning_rate': 9.002962962962963e-06, 'epoch': 1.06}\n",
      "{'loss': 0.22, 'grad_norm': 8.483721733093262, 'learning_rate': 8.984444444444446e-06, 'epoch': 1.06}\n",
      "{'loss': 0.2279, 'grad_norm': 8.902152061462402, 'learning_rate': 8.965925925925926e-06, 'epoch': 1.06}\n",
      "{'loss': 0.2324, 'grad_norm': 6.304404258728027, 'learning_rate': 8.947407407407409e-06, 'epoch': 1.06}\n",
      "{'loss': 0.2107, 'grad_norm': 5.499401569366455, 'learning_rate': 8.92888888888889e-06, 'epoch': 1.06}\n",
      "{'loss': 0.2018, 'grad_norm': 5.736880302429199, 'learning_rate': 8.910370370370372e-06, 'epoch': 1.07}\n",
      "{'loss': 0.1875, 'grad_norm': 4.773323059082031, 'learning_rate': 8.891851851851853e-06, 'epoch': 1.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Too many dataloader workers: 16 (max is dataset.n_shards=1). Stopping 15 dataloader workers.\n",
      "Reading metadata...: 8353it [00:01, 5843.87it/s]\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2925000786781311, 'eval_wer': 73.49821013299888, 'eval_runtime': 1312.3257, 'eval_samples_per_second': 6.365, 'eval_steps_per_second': 0.399, 'epoch': 1.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahanaf/Torch/torch2_2/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2451, 'grad_norm': 5.474468231201172, 'learning_rate': 8.873333333333334e-06, 'epoch': 1.07}\n",
      "{'loss': 0.2052, 'grad_norm': 7.113743305206299, 'learning_rate': 8.854814814814816e-06, 'epoch': 1.07}\n",
      "{'loss': 0.2322, 'grad_norm': 8.86280632019043, 'learning_rate': 8.836296296296297e-06, 'epoch': 1.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Too many dataloader workers: 16 (max is dataset.n_shards=1). Stopping 15 dataloader workers.\n",
      "Reading metadata...: 16777it [00:03, 5113.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2738, 'grad_norm': 4.630594730377197, 'learning_rate': 8.817777777777778e-06, 'epoch': 2.0}\n",
      "{'loss': 0.2382, 'grad_norm': 6.5984320640563965, 'learning_rate': 8.79925925925926e-06, 'epoch': 2.0}\n",
      "{'loss': 0.2391, 'grad_norm': 6.413021564483643, 'learning_rate': 8.780740740740743e-06, 'epoch': 2.0}\n",
      "{'loss': 0.2415, 'grad_norm': 7.237079620361328, 'learning_rate': 8.762222222222223e-06, 'epoch': 2.01}\n",
      "{'loss': 0.2451, 'grad_norm': 7.047138214111328, 'learning_rate': 8.743703703703704e-06, 'epoch': 2.01}\n",
      "{'loss': 0.2394, 'grad_norm': 5.21874475479126, 'learning_rate': 8.725185185185185e-06, 'epoch': 2.01}\n",
      "{'loss': 0.2448, 'grad_norm': 5.7790913581848145, 'learning_rate': 8.706666666666667e-06, 'epoch': 2.01}\n",
      "{'loss': 0.225, 'grad_norm': 8.713177680969238, 'learning_rate': 8.688148148148148e-06, 'epoch': 2.01}\n",
      "{'loss': 0.2349, 'grad_norm': 7.787460803985596, 'learning_rate': 8.66962962962963e-06, 'epoch': 2.01}\n",
      "{'loss': 0.2264, 'grad_norm': 6.919358730316162, 'learning_rate': 8.651111111111113e-06, 'epoch': 2.02}\n",
      "{'loss': 0.2099, 'grad_norm': 6.322697162628174, 'learning_rate': 8.632592592592594e-06, 'epoch': 2.02}\n",
      "{'loss': 0.2206, 'grad_norm': 5.627058506011963, 'learning_rate': 8.614074074074075e-06, 'epoch': 2.02}\n",
      "{'loss': 0.2222, 'grad_norm': 7.438137054443359, 'learning_rate': 8.595555555555556e-06, 'epoch': 2.02}\n",
      "{'loss': 0.2349, 'grad_norm': 11.401512145996094, 'learning_rate': 8.577037037037038e-06, 'epoch': 2.02}\n",
      "{'loss': 0.2318, 'grad_norm': 6.4794416427612305, 'learning_rate': 8.558518518518519e-06, 'epoch': 2.03}\n",
      "{'loss': 0.2118, 'grad_norm': 8.55227279663086, 'learning_rate': 8.540000000000001e-06, 'epoch': 2.03}\n",
      "{'loss': 0.2105, 'grad_norm': 6.102731227874756, 'learning_rate': 8.521481481481482e-06, 'epoch': 2.03}\n",
      "{'loss': 0.2076, 'grad_norm': 6.1944732666015625, 'learning_rate': 8.502962962962964e-06, 'epoch': 2.03}\n",
      "{'loss': 0.2077, 'grad_norm': 6.949308395385742, 'learning_rate': 8.484444444444445e-06, 'epoch': 2.03}\n",
      "{'loss': 0.2315, 'grad_norm': 8.355603218078613, 'learning_rate': 8.465925925925926e-06, 'epoch': 2.03}\n",
      "{'loss': 0.2003, 'grad_norm': 6.343765735626221, 'learning_rate': 8.447407407407409e-06, 'epoch': 2.04}\n",
      "{'loss': 0.213, 'grad_norm': 5.904392719268799, 'learning_rate': 8.42888888888889e-06, 'epoch': 2.04}\n",
      "{'loss': 0.2052, 'grad_norm': 5.0814528465271, 'learning_rate': 8.410370370370372e-06, 'epoch': 2.04}\n",
      "{'loss': 0.2135, 'grad_norm': 5.401792049407959, 'learning_rate': 8.391851851851853e-06, 'epoch': 2.04}\n",
      "{'loss': 0.1975, 'grad_norm': 4.5557990074157715, 'learning_rate': 8.373333333333335e-06, 'epoch': 2.04}\n",
      "{'loss': 0.1839, 'grad_norm': 7.102982521057129, 'learning_rate': 8.354814814814816e-06, 'epoch': 2.04}\n",
      "{'loss': 0.2301, 'grad_norm': 5.7918195724487305, 'learning_rate': 8.337037037037039e-06, 'epoch': 2.05}\n",
      "{'loss': 0.2141, 'grad_norm': 5.95110559463501, 'learning_rate': 8.31851851851852e-06, 'epoch': 2.05}\n",
      "{'loss': 0.239, 'grad_norm': 4.533879280090332, 'learning_rate': 8.3e-06, 'epoch': 2.05}\n",
      "{'loss': 0.1907, 'grad_norm': 7.2275238037109375, 'learning_rate': 8.281481481481483e-06, 'epoch': 2.05}\n",
      "{'loss': 0.1693, 'grad_norm': 7.311295986175537, 'learning_rate': 8.262962962962963e-06, 'epoch': 2.05}\n",
      "{'loss': 0.1654, 'grad_norm': 3.496776580810547, 'learning_rate': 8.244444444444444e-06, 'epoch': 2.06}\n",
      "{'loss': 0.1666, 'grad_norm': 5.833822250366211, 'learning_rate': 8.225925925925927e-06, 'epoch': 2.06}\n",
      "{'loss': 0.1674, 'grad_norm': 6.350719928741455, 'learning_rate': 8.207407407407409e-06, 'epoch': 2.06}\n",
      "{'loss': 0.1809, 'grad_norm': 6.934649467468262, 'learning_rate': 8.18888888888889e-06, 'epoch': 2.06}\n",
      "{'loss': 0.1774, 'grad_norm': 4.654376983642578, 'learning_rate': 8.17037037037037e-06, 'epoch': 2.06}\n",
      "{'loss': 0.163, 'grad_norm': 5.242435932159424, 'learning_rate': 8.151851851851853e-06, 'epoch': 2.06}\n",
      "{'loss': 0.1533, 'grad_norm': 4.54705286026001, 'learning_rate': 8.133333333333334e-06, 'epoch': 2.07}\n",
      "{'loss': 0.1424, 'grad_norm': 5.536778450012207, 'learning_rate': 8.114814814814815e-06, 'epoch': 2.07}\n",
      "{'loss': 0.1933, 'grad_norm': 5.929997444152832, 'learning_rate': 8.096296296296297e-06, 'epoch': 2.07}\n",
      "{'loss': 0.1625, 'grad_norm': 5.67618989944458, 'learning_rate': 8.077777777777778e-06, 'epoch': 2.07}\n",
      "{'loss': 0.181, 'grad_norm': 10.5267972946167, 'learning_rate': 8.05925925925926e-06, 'epoch': 2.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Too many dataloader workers: 16 (max is dataset.n_shards=1). Stopping 15 dataloader workers.\n",
      "Reading metadata...: 16777it [00:02, 5804.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2192, 'grad_norm': 6.289376258850098, 'learning_rate': 8.040740740740741e-06, 'epoch': 3.0}\n",
      "{'loss': 0.1874, 'grad_norm': 5.311645030975342, 'learning_rate': 8.022222222222222e-06, 'epoch': 3.0}\n",
      "{'loss': 0.1953, 'grad_norm': 7.021289825439453, 'learning_rate': 8.003703703703704e-06, 'epoch': 3.0}\n",
      "{'loss': 0.192, 'grad_norm': 7.291260719299316, 'learning_rate': 7.985185185185185e-06, 'epoch': 3.01}\n",
      "{'loss': 0.1971, 'grad_norm': 5.0645365715026855, 'learning_rate': 7.966666666666668e-06, 'epoch': 3.01}\n",
      "{'loss': 0.1971, 'grad_norm': 5.627686023712158, 'learning_rate': 7.948148148148149e-06, 'epoch': 3.01}\n",
      "{'loss': 0.1988, 'grad_norm': 5.452093601226807, 'learning_rate': 7.929629629629631e-06, 'epoch': 3.01}\n",
      "{'loss': 0.178, 'grad_norm': 4.289679050445557, 'learning_rate': 7.911111111111112e-06, 'epoch': 3.01}\n",
      "{'loss': 0.1885, 'grad_norm': 5.572542667388916, 'learning_rate': 7.892592592592593e-06, 'epoch': 3.01}\n",
      "{'loss': 0.1813, 'grad_norm': 4.247471332550049, 'learning_rate': 7.874074074074075e-06, 'epoch': 3.02}\n",
      "{'loss': 0.172, 'grad_norm': 5.914666652679443, 'learning_rate': 7.855555555555556e-06, 'epoch': 3.02}\n",
      "{'loss': 0.1799, 'grad_norm': 8.400858879089355, 'learning_rate': 7.837037037037037e-06, 'epoch': 3.02}\n",
      "{'loss': 0.183, 'grad_norm': 8.442802429199219, 'learning_rate': 7.818518518518519e-06, 'epoch': 3.02}\n",
      "{'loss': 0.1931, 'grad_norm': 7.167121410369873, 'learning_rate': 7.800000000000002e-06, 'epoch': 3.02}\n",
      "{'loss': 0.1901, 'grad_norm': 4.794524669647217, 'learning_rate': 7.781481481481482e-06, 'epoch': 3.03}\n",
      "{'loss': 0.1702, 'grad_norm': 5.763552665710449, 'learning_rate': 7.762962962962963e-06, 'epoch': 3.03}\n",
      "{'loss': 0.1681, 'grad_norm': 4.950320243835449, 'learning_rate': 7.744444444444446e-06, 'epoch': 3.03}\n",
      "{'loss': 0.1713, 'grad_norm': 7.409005165100098, 'learning_rate': 7.725925925925926e-06, 'epoch': 3.03}\n",
      "{'loss': 0.1643, 'grad_norm': 6.032288551330566, 'learning_rate': 7.707407407407407e-06, 'epoch': 3.03}\n",
      "{'loss': 0.1927, 'grad_norm': 6.225192070007324, 'learning_rate': 7.68888888888889e-06, 'epoch': 3.03}\n",
      "{'loss': 0.1612, 'grad_norm': 6.225448131561279, 'learning_rate': 7.670370370370372e-06, 'epoch': 3.04}\n",
      "{'loss': 0.1746, 'grad_norm': 8.591054916381836, 'learning_rate': 7.651851851851853e-06, 'epoch': 3.04}\n",
      "{'loss': 0.1723, 'grad_norm': 10.68940258026123, 'learning_rate': 7.633333333333334e-06, 'epoch': 3.04}\n",
      "{'loss': 0.17, 'grad_norm': 6.854393005371094, 'learning_rate': 7.614814814814816e-06, 'epoch': 3.04}\n",
      "{'loss': 0.1608, 'grad_norm': 5.378332138061523, 'learning_rate': 7.596296296296297e-06, 'epoch': 3.04}\n",
      "{'loss': 0.1533, 'grad_norm': 6.05957555770874, 'learning_rate': 7.5777777777777785e-06, 'epoch': 3.04}\n",
      "{'loss': 0.1941, 'grad_norm': 5.33628511428833, 'learning_rate': 7.559259259259259e-06, 'epoch': 3.05}\n",
      "{'loss': 0.1787, 'grad_norm': 6.5787672996521, 'learning_rate': 7.540740740740742e-06, 'epoch': 3.05}\n",
      "{'loss': 0.1981, 'grad_norm': 4.32175350189209, 'learning_rate': 7.5222222222222226e-06, 'epoch': 3.05}\n",
      "{'loss': 0.163, 'grad_norm': 8.296712875366211, 'learning_rate': 7.503703703703704e-06, 'epoch': 3.05}\n",
      "{'loss': 0.132, 'grad_norm': 3.940277099609375, 'learning_rate': 7.485185185185185e-06, 'epoch': 3.05}\n",
      "{'loss': 0.1324, 'grad_norm': 3.5594406127929688, 'learning_rate': 7.4666666666666675e-06, 'epoch': 3.06}\n",
      "{'loss': 0.1367, 'grad_norm': 3.2749950885772705, 'learning_rate': 7.448148148148149e-06, 'epoch': 3.06}\n",
      "{'loss': 0.1355, 'grad_norm': 4.1259765625, 'learning_rate': 7.42962962962963e-06, 'epoch': 3.06}\n",
      "{'loss': 0.1501, 'grad_norm': 4.934811115264893, 'learning_rate': 7.411111111111112e-06, 'epoch': 3.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Too many dataloader workers: 16 (max is dataset.n_shards=1). Stopping 15 dataloader workers.\n",
      "Reading metadata...: 8353it [00:01, 5578.84it/s]\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2365058958530426, 'eval_wer': 64.5985210733976, 'eval_runtime': 1323.8443, 'eval_samples_per_second': 6.31, 'eval_steps_per_second': 0.395, 'epoch': 3.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahanaf/Torch/torch2_2/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1427, 'grad_norm': 3.825378656387329, 'learning_rate': 7.392592592592593e-06, 'epoch': 3.06}\n",
      "{'loss': 0.1319, 'grad_norm': 4.309532165527344, 'learning_rate': 7.374074074074075e-06, 'epoch': 3.06}\n",
      "{'loss': 0.1228, 'grad_norm': 4.618266582489014, 'learning_rate': 7.3555555555555555e-06, 'epoch': 3.07}\n",
      "{'loss': 0.1127, 'grad_norm': 4.182879447937012, 'learning_rate': 7.337037037037038e-06, 'epoch': 3.07}\n",
      "{'loss': 0.1593, 'grad_norm': 3.9108448028564453, 'learning_rate': 7.31851851851852e-06, 'epoch': 3.07}\n",
      "{'loss': 0.1348, 'grad_norm': 6.079570770263672, 'learning_rate': 7.3e-06, 'epoch': 3.07}\n",
      "{'loss': 0.1486, 'grad_norm': 10.472845077514648, 'learning_rate': 7.281481481481481e-06, 'epoch': 3.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Too many dataloader workers: 16 (max is dataset.n_shards=1). Stopping 15 dataloader workers.\n",
      "Reading metadata...: 16777it [00:03, 5050.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1812, 'grad_norm': 4.919039249420166, 'learning_rate': 7.262962962962964e-06, 'epoch': 4.0}\n",
      "{'loss': 0.1608, 'grad_norm': 8.230866432189941, 'learning_rate': 7.244444444444445e-06, 'epoch': 4.0}\n",
      "{'loss': 0.1575, 'grad_norm': 5.41856050491333, 'learning_rate': 7.225925925925926e-06, 'epoch': 4.0}\n",
      "{'loss': 0.1625, 'grad_norm': 6.354863166809082, 'learning_rate': 7.2074074074074085e-06, 'epoch': 4.01}\n",
      "{'loss': 0.1635, 'grad_norm': 4.77559232711792, 'learning_rate': 7.188888888888889e-06, 'epoch': 4.01}\n",
      "{'loss': 0.1667, 'grad_norm': 4.2390360832214355, 'learning_rate': 7.170370370370371e-06, 'epoch': 4.01}\n",
      "{'loss': 0.1688, 'grad_norm': 6.373630523681641, 'learning_rate': 7.151851851851852e-06, 'epoch': 4.01}\n",
      "{'loss': 0.149, 'grad_norm': 5.78662109375, 'learning_rate': 7.133333333333334e-06, 'epoch': 4.01}\n",
      "{'loss': 0.1548, 'grad_norm': 4.940515518188477, 'learning_rate': 7.114814814814816e-06, 'epoch': 4.01}\n",
      "{'loss': 0.1502, 'grad_norm': 3.899848222732544, 'learning_rate': 7.096296296296297e-06, 'epoch': 4.02}\n",
      "{'loss': 0.1446, 'grad_norm': 4.656623363494873, 'learning_rate': 7.077777777777778e-06, 'epoch': 4.02}\n",
      "{'loss': 0.1527, 'grad_norm': 7.404901027679443, 'learning_rate': 7.05925925925926e-06, 'epoch': 4.02}\n",
      "{'loss': 0.1555, 'grad_norm': 4.9156413078308105, 'learning_rate': 7.0407407407407415e-06, 'epoch': 4.02}\n",
      "{'loss': 0.1661, 'grad_norm': 6.529609203338623, 'learning_rate': 7.022222222222222e-06, 'epoch': 4.02}\n",
      "{'loss': 0.1582, 'grad_norm': 6.063333511352539, 'learning_rate': 7.003703703703705e-06, 'epoch': 4.03}\n",
      "{'loss': 0.1404, 'grad_norm': 6.459277629852295, 'learning_rate': 6.9851851851851855e-06, 'epoch': 4.03}\n",
      "{'loss': 0.1408, 'grad_norm': 5.3420329093933105, 'learning_rate': 6.966666666666667e-06, 'epoch': 4.03}\n",
      "{'loss': 0.1442, 'grad_norm': 6.079737663269043, 'learning_rate': 6.948148148148148e-06, 'epoch': 4.03}\n",
      "{'loss': 0.136, 'grad_norm': 4.660114765167236, 'learning_rate': 6.92962962962963e-06, 'epoch': 4.03}\n",
      "{'loss': 0.162, 'grad_norm': 4.425811767578125, 'learning_rate': 6.911111111111112e-06, 'epoch': 4.03}\n",
      "{'loss': 0.1347, 'grad_norm': 6.189593315124512, 'learning_rate': 6.892592592592593e-06, 'epoch': 4.04}\n",
      "{'loss': 0.1496, 'grad_norm': 4.730854034423828, 'learning_rate': 6.8740740740740745e-06, 'epoch': 4.04}\n",
      "{'loss': 0.1521, 'grad_norm': 7.823866367340088, 'learning_rate': 6.855555555555556e-06, 'epoch': 4.04}\n",
      "{'loss': 0.1384, 'grad_norm': 5.496204376220703, 'learning_rate': 6.837037037037038e-06, 'epoch': 4.04}\n",
      "{'loss': 0.1345, 'grad_norm': 7.393240928649902, 'learning_rate': 6.8185185185185185e-06, 'epoch': 4.04}\n",
      "{'loss': 0.1286, 'grad_norm': 5.358458518981934, 'learning_rate': 6.800000000000001e-06, 'epoch': 4.04}\n",
      "{'loss': 0.1708, 'grad_norm': 7.235446453094482, 'learning_rate': 6.781481481481483e-06, 'epoch': 4.05}\n",
      "{'loss': 0.1604, 'grad_norm': 10.304182052612305, 'learning_rate': 6.762962962962963e-06, 'epoch': 4.05}\n",
      "{'loss': 0.1588, 'grad_norm': 5.077969551086426, 'learning_rate': 6.744444444444444e-06, 'epoch': 4.05}\n",
      "{'loss': 0.1382, 'grad_norm': 4.685784339904785, 'learning_rate': 6.725925925925927e-06, 'epoch': 4.05}\n",
      "{'loss': 0.1084, 'grad_norm': 4.038897514343262, 'learning_rate': 6.707407407407408e-06, 'epoch': 4.05}\n",
      "{'loss': 0.1097, 'grad_norm': 5.105076789855957, 'learning_rate': 6.688888888888889e-06, 'epoch': 4.06}\n",
      "{'loss': 0.1139, 'grad_norm': 3.4958720207214355, 'learning_rate': 6.670370370370371e-06, 'epoch': 4.06}\n",
      "{'loss': 0.1151, 'grad_norm': 4.78465461730957, 'learning_rate': 6.651851851851852e-06, 'epoch': 4.06}\n",
      "{'loss': 0.129, 'grad_norm': 6.179281234741211, 'learning_rate': 6.633333333333334e-06, 'epoch': 4.06}\n",
      "{'loss': 0.1141, 'grad_norm': 4.358274936676025, 'learning_rate': 6.614814814814815e-06, 'epoch': 4.06}\n",
      "{'loss': 0.1104, 'grad_norm': 5.662635326385498, 'learning_rate': 6.596296296296297e-06, 'epoch': 4.06}\n",
      "{'loss': 0.0999, 'grad_norm': 6.912407875061035, 'learning_rate': 6.577777777777779e-06, 'epoch': 4.07}\n",
      "{'loss': 0.0902, 'grad_norm': 3.564737319946289, 'learning_rate': 6.55925925925926e-06, 'epoch': 4.07}\n",
      "{'loss': 0.1367, 'grad_norm': 6.34589958190918, 'learning_rate': 6.540740740740741e-06, 'epoch': 4.07}\n",
      "{'loss': 0.1116, 'grad_norm': 4.103939056396484, 'learning_rate': 6.522222222222223e-06, 'epoch': 4.07}\n",
      "{'loss': 0.1266, 'grad_norm': 4.958124160766602, 'learning_rate': 6.5037037037037045e-06, 'epoch': 4.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Too many dataloader workers: 16 (max is dataset.n_shards=1). Stopping 15 dataloader workers.\n",
      "Reading metadata...: 16777it [00:03, 4981.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1559, 'grad_norm': 5.27297306060791, 'learning_rate': 6.485185185185185e-06, 'epoch': 5.0}\n",
      "{'loss': 0.1363, 'grad_norm': 7.181188106536865, 'learning_rate': 6.466666666666667e-06, 'epoch': 5.0}\n",
      "{'loss': 0.1319, 'grad_norm': 6.004862308502197, 'learning_rate': 6.448148148148149e-06, 'epoch': 5.0}\n",
      "{'loss': 0.1392, 'grad_norm': 4.471071243286133, 'learning_rate': 6.42962962962963e-06, 'epoch': 5.01}\n",
      "{'loss': 0.1396, 'grad_norm': 6.697170734405518, 'learning_rate': 6.411111111111111e-06, 'epoch': 5.01}\n",
      "{'loss': 0.145, 'grad_norm': 5.697316646575928, 'learning_rate': 6.393333333333334e-06, 'epoch': 5.01}\n",
      "{'loss': 0.1466, 'grad_norm': 5.980069160461426, 'learning_rate': 6.3748148148148145e-06, 'epoch': 5.01}\n",
      "{'loss': 0.1245, 'grad_norm': 5.761324405670166, 'learning_rate': 6.356296296296297e-06, 'epoch': 5.01}\n",
      "{'loss': 0.1299, 'grad_norm': 4.646592617034912, 'learning_rate': 6.3377777777777786e-06, 'epoch': 5.01}\n",
      "{'loss': 0.1279, 'grad_norm': 4.830352783203125, 'learning_rate': 6.319259259259259e-06, 'epoch': 5.02}\n",
      "{'loss': 0.1213, 'grad_norm': 3.538966417312622, 'learning_rate': 6.300740740740742e-06, 'epoch': 5.02}\n",
      "{'loss': 0.1355, 'grad_norm': 6.417136192321777, 'learning_rate': 6.282222222222223e-06, 'epoch': 5.02}\n",
      "{'loss': 0.1315, 'grad_norm': 6.094174385070801, 'learning_rate': 6.263703703703704e-06, 'epoch': 5.02}\n",
      "{'loss': 0.1403, 'grad_norm': 4.328838348388672, 'learning_rate': 6.245185185185185e-06, 'epoch': 5.02}\n",
      "{'loss': 0.1354, 'grad_norm': 2.7569684982299805, 'learning_rate': 6.2266666666666675e-06, 'epoch': 5.03}\n",
      "{'loss': 0.1221, 'grad_norm': 5.962710380554199, 'learning_rate': 6.208148148148149e-06, 'epoch': 5.03}\n",
      "{'loss': 0.1204, 'grad_norm': 4.401760101318359, 'learning_rate': 6.18962962962963e-06, 'epoch': 5.03}\n",
      "{'loss': 0.1221, 'grad_norm': 4.27582311630249, 'learning_rate': 6.171111111111112e-06, 'epoch': 5.03}\n",
      "{'loss': 0.115, 'grad_norm': 5.414527893066406, 'learning_rate': 6.152592592592593e-06, 'epoch': 5.03}\n",
      "{'loss': 0.1382, 'grad_norm': 4.54753303527832, 'learning_rate': 6.134074074074075e-06, 'epoch': 5.03}\n",
      "{'loss': 0.1175, 'grad_norm': 6.341527462005615, 'learning_rate': 6.1155555555555555e-06, 'epoch': 5.04}\n",
      "{'loss': 0.131, 'grad_norm': 5.285993576049805, 'learning_rate': 6.097037037037038e-06, 'epoch': 5.04}\n",
      "{'loss': 0.1325, 'grad_norm': 5.741633892059326, 'learning_rate': 6.078518518518519e-06, 'epoch': 5.04}\n",
      "{'loss': 0.1168, 'grad_norm': 4.388262748718262, 'learning_rate': 6.0600000000000004e-06, 'epoch': 5.04}\n",
      "{'loss': 0.1215, 'grad_norm': 10.020905494689941, 'learning_rate': 6.041481481481481e-06, 'epoch': 5.04}\n",
      "{'loss': 0.1022, 'grad_norm': 3.9454591274261475, 'learning_rate': 6.022962962962964e-06, 'epoch': 5.04}\n",
      "{'loss': 0.1496, 'grad_norm': 4.846457481384277, 'learning_rate': 6.004444444444445e-06, 'epoch': 5.05}\n",
      "{'loss': 0.1529, 'grad_norm': 11.69445514678955, 'learning_rate': 5.985925925925926e-06, 'epoch': 5.05}\n",
      "{'loss': 0.1241, 'grad_norm': 4.087924480438232, 'learning_rate': 5.9674074074074086e-06, 'epoch': 5.05}\n",
      "{'loss': 0.1216, 'grad_norm': 5.870538234710693, 'learning_rate': 5.948888888888889e-06, 'epoch': 5.05}\n",
      "{'loss': 0.0913, 'grad_norm': 5.567917346954346, 'learning_rate': 5.930370370370371e-06, 'epoch': 5.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Too many dataloader workers: 16 (max is dataset.n_shards=1). Stopping 15 dataloader workers.\n",
      "Reading metadata...: 8353it [00:01, 5614.78it/s]\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22959953546524048, 'eval_wer': 62.2873716391001, 'eval_runtime': 1345.5731, 'eval_samples_per_second': 6.208, 'eval_steps_per_second': 0.389, 'epoch': 5.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahanaf/Torch/torch2_2/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0885, 'grad_norm': 5.1116251945495605, 'learning_rate': 5.911851851851852e-06, 'epoch': 5.06}\n",
      "{'loss': 0.0974, 'grad_norm': 3.935164451599121, 'learning_rate': 5.893333333333334e-06, 'epoch': 5.06}\n",
      "{'loss': 0.0989, 'grad_norm': 5.062479496002197, 'learning_rate': 5.874814814814815e-06, 'epoch': 5.06}\n",
      "{'loss': 0.1159, 'grad_norm': 7.613689422607422, 'learning_rate': 5.856296296296297e-06, 'epoch': 5.06}\n",
      "{'loss': 0.0922, 'grad_norm': 3.0451881885528564, 'learning_rate': 5.837777777777777e-06, 'epoch': 5.06}\n",
      "{'loss': 0.095, 'grad_norm': 5.405396461486816, 'learning_rate': 5.81925925925926e-06, 'epoch': 5.06}\n",
      "{'loss': 0.0808, 'grad_norm': 3.916132926940918, 'learning_rate': 5.8007407407407415e-06, 'epoch': 5.07}\n",
      "{'loss': 0.074, 'grad_norm': 3.6781935691833496, 'learning_rate': 5.782222222222222e-06, 'epoch': 5.07}\n",
      "{'loss': 0.1189, 'grad_norm': 5.998669147491455, 'learning_rate': 5.763703703703705e-06, 'epoch': 5.07}\n",
      "{'loss': 0.0953, 'grad_norm': 7.116799831390381, 'learning_rate': 5.7451851851851855e-06, 'epoch': 5.07}\n",
      "{'loss': 0.112, 'grad_norm': 5.631762504577637, 'learning_rate': 5.726666666666667e-06, 'epoch': 5.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Too many dataloader workers: 16 (max is dataset.n_shards=1). Stopping 15 dataloader workers.\n",
      "Reading metadata...: 16777it [00:02, 6027.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.132, 'grad_norm': 3.5933284759521484, 'learning_rate': 5.708148148148148e-06, 'epoch': 6.0}\n",
      "{'loss': 0.119, 'grad_norm': 7.152806758880615, 'learning_rate': 5.6896296296296304e-06, 'epoch': 6.0}\n",
      "{'loss': 0.1142, 'grad_norm': 5.3274407386779785, 'learning_rate': 5.671111111111112e-06, 'epoch': 6.0}\n",
      "{'loss': 0.121, 'grad_norm': 6.657630443572998, 'learning_rate': 5.652592592592593e-06, 'epoch': 6.01}\n",
      "{'loss': 0.1193, 'grad_norm': 8.845831871032715, 'learning_rate': 5.634074074074074e-06, 'epoch': 6.01}\n",
      "{'loss': 0.1275, 'grad_norm': 6.962968826293945, 'learning_rate': 5.615555555555556e-06, 'epoch': 6.01}\n",
      "{'loss': 0.1255, 'grad_norm': 4.574744701385498, 'learning_rate': 5.597037037037038e-06, 'epoch': 6.01}\n",
      "{'loss': 0.1055, 'grad_norm': 4.433323860168457, 'learning_rate': 5.5785185185185185e-06, 'epoch': 6.01}\n",
      "{'loss': 0.1123, 'grad_norm': 5.174184322357178, 'learning_rate': 5.560000000000001e-06, 'epoch': 6.01}\n",
      "{'loss': 0.1083, 'grad_norm': 4.430150032043457, 'learning_rate': 5.541481481481482e-06, 'epoch': 6.02}\n",
      "{'loss': 0.1056, 'grad_norm': 5.919404983520508, 'learning_rate': 5.522962962962963e-06, 'epoch': 6.02}\n",
      "{'loss': 0.1148, 'grad_norm': 4.21290397644043, 'learning_rate': 5.504444444444444e-06, 'epoch': 6.02}\n",
      "{'loss': 0.1153, 'grad_norm': 5.093934535980225, 'learning_rate': 5.485925925925927e-06, 'epoch': 6.02}\n",
      "{'loss': 0.1206, 'grad_norm': 5.400303363800049, 'learning_rate': 5.467407407407408e-06, 'epoch': 6.02}\n",
      "{'loss': 0.117, 'grad_norm': 3.8510162830352783, 'learning_rate': 5.448888888888889e-06, 'epoch': 6.03}\n",
      "{'loss': 0.1094, 'grad_norm': 6.3189616203308105, 'learning_rate': 5.430370370370371e-06, 'epoch': 6.03}\n",
      "{'loss': 0.1003, 'grad_norm': 4.533552646636963, 'learning_rate': 5.411851851851852e-06, 'epoch': 6.03}\n",
      "{'loss': 0.1044, 'grad_norm': 4.118469715118408, 'learning_rate': 5.393333333333334e-06, 'epoch': 6.03}\n",
      "{'loss': 0.0988, 'grad_norm': 4.749215126037598, 'learning_rate': 5.374814814814815e-06, 'epoch': 6.03}\n",
      "{'loss': 0.1183, 'grad_norm': 3.7559027671813965, 'learning_rate': 5.356296296296297e-06, 'epoch': 6.03}\n",
      "{'loss': 0.1066, 'grad_norm': 5.656510353088379, 'learning_rate': 5.337777777777779e-06, 'epoch': 6.04}\n",
      "{'loss': 0.1163, 'grad_norm': 5.473826885223389, 'learning_rate': 5.31925925925926e-06, 'epoch': 6.04}\n",
      "{'loss': 0.1126, 'grad_norm': 2.5535926818847656, 'learning_rate': 5.30074074074074e-06, 'epoch': 6.04}\n",
      "{'loss': 0.1027, 'grad_norm': 4.226991653442383, 'learning_rate': 5.282222222222223e-06, 'epoch': 6.04}\n",
      "{'loss': 0.1075, 'grad_norm': 5.602957725524902, 'learning_rate': 5.2637037037037045e-06, 'epoch': 6.04}\n",
      "{'loss': 0.086, 'grad_norm': 4.816860198974609, 'learning_rate': 5.245185185185185e-06, 'epoch': 6.05}\n",
      "{'loss': 0.1346, 'grad_norm': 5.969823360443115, 'learning_rate': 5.226666666666667e-06, 'epoch': 6.05}\n",
      "{'loss': 0.1337, 'grad_norm': 6.105003356933594, 'learning_rate': 5.2081481481481485e-06, 'epoch': 6.05}\n",
      "{'loss': 0.1089, 'grad_norm': 5.598677158355713, 'learning_rate': 5.18962962962963e-06, 'epoch': 6.05}\n",
      "{'loss': 0.1058, 'grad_norm': 5.584506511688232, 'learning_rate': 5.171111111111111e-06, 'epoch': 6.05}\n",
      "{'loss': 0.0765, 'grad_norm': 4.096843242645264, 'learning_rate': 5.152592592592593e-06, 'epoch': 6.05}\n",
      "{'loss': 0.0733, 'grad_norm': 4.692636489868164, 'learning_rate': 5.134074074074075e-06, 'epoch': 6.06}\n",
      "{'loss': 0.0848, 'grad_norm': 6.159757614135742, 'learning_rate': 5.115555555555556e-06, 'epoch': 6.06}\n",
      "{'loss': 0.0872, 'grad_norm': 6.306578636169434, 'learning_rate': 5.0970370370370374e-06, 'epoch': 6.06}\n",
      "{'loss': 0.1049, 'grad_norm': 9.06215763092041, 'learning_rate': 5.078518518518519e-06, 'epoch': 6.06}\n",
      "{'loss': 0.0735, 'grad_norm': 4.185119152069092, 'learning_rate': 5.060000000000001e-06, 'epoch': 6.06}\n",
      "{'loss': 0.0815, 'grad_norm': 4.862882614135742, 'learning_rate': 5.0414814814814815e-06, 'epoch': 6.06}\n",
      "{'loss': 0.0671, 'grad_norm': 4.027316093444824, 'learning_rate': 5.022962962962964e-06, 'epoch': 6.07}\n",
      "{'loss': 0.0626, 'grad_norm': 4.690160751342773, 'learning_rate': 5.004444444444445e-06, 'epoch': 6.07}\n",
      "{'loss': 0.104, 'grad_norm': 5.417194366455078, 'learning_rate': 4.985925925925926e-06, 'epoch': 6.07}\n",
      "{'loss': 0.0825, 'grad_norm': 6.696625709533691, 'learning_rate': 4.967407407407408e-06, 'epoch': 6.07}\n",
      "{'loss': 0.098, 'grad_norm': 5.217647552490234, 'learning_rate': 4.94888888888889e-06, 'epoch': 6.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Too many dataloader workers: 16 (max is dataset.n_shards=1). Stopping 15 dataloader workers.\n",
      "Reading metadata...: 16777it [00:03, 4251.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1129, 'grad_norm': 3.9762778282165527, 'learning_rate': 4.930370370370371e-06, 'epoch': 7.0}\n",
      "{'loss': 0.1053, 'grad_norm': 4.898495674133301, 'learning_rate': 4.911851851851852e-06, 'epoch': 7.0}\n",
      "{'loss': 0.1005, 'grad_norm': 6.6659393310546875, 'learning_rate': 4.893333333333334e-06, 'epoch': 7.0}\n",
      "{'loss': 0.1063, 'grad_norm': 5.901172637939453, 'learning_rate': 4.874814814814815e-06, 'epoch': 7.01}\n",
      "{'loss': 0.1021, 'grad_norm': 5.760653495788574, 'learning_rate': 4.856296296296297e-06, 'epoch': 7.01}\n",
      "{'loss': 0.1118, 'grad_norm': 5.071141242980957, 'learning_rate': 4.837777777777778e-06, 'epoch': 7.01}\n",
      "{'loss': 0.1098, 'grad_norm': 6.1484174728393555, 'learning_rate': 4.819259259259259e-06, 'epoch': 7.01}\n",
      "{'loss': 0.0878, 'grad_norm': 3.0109376907348633, 'learning_rate': 4.800740740740742e-06, 'epoch': 7.01}\n",
      "{'loss': 0.0997, 'grad_norm': 5.982563018798828, 'learning_rate': 4.7822222222222226e-06, 'epoch': 7.01}\n",
      "{'loss': 0.0918, 'grad_norm': 3.2056679725646973, 'learning_rate': 4.763703703703704e-06, 'epoch': 7.02}\n",
      "{'loss': 0.0919, 'grad_norm': 4.200450420379639, 'learning_rate': 4.745185185185186e-06, 'epoch': 7.02}\n",
      "{'loss': 0.0998, 'grad_norm': 5.633141994476318, 'learning_rate': 4.7266666666666674e-06, 'epoch': 7.02}\n",
      "{'loss': 0.0994, 'grad_norm': 4.2753143310546875, 'learning_rate': 4.708148148148148e-06, 'epoch': 7.02}\n",
      "{'loss': 0.1038, 'grad_norm': 4.0614495277404785, 'learning_rate': 4.68962962962963e-06, 'epoch': 7.02}\n",
      "{'loss': 0.1015, 'grad_norm': 3.952998638153076, 'learning_rate': 4.6711111111111115e-06, 'epoch': 7.03}\n",
      "{'loss': 0.0988, 'grad_norm': 6.532681465148926, 'learning_rate': 4.652592592592593e-06, 'epoch': 7.03}\n",
      "{'loss': 0.0828, 'grad_norm': 3.966606616973877, 'learning_rate': 4.634074074074075e-06, 'epoch': 7.03}\n",
      "{'loss': 0.0914, 'grad_norm': 4.75431489944458, 'learning_rate': 4.6155555555555555e-06, 'epoch': 7.03}\n",
      "{'loss': 0.0825, 'grad_norm': 2.5740528106689453, 'learning_rate': 4.597037037037038e-06, 'epoch': 7.03}\n",
      "{'loss': 0.1063, 'grad_norm': 6.48344087600708, 'learning_rate': 4.578518518518519e-06, 'epoch': 7.03}\n",
      "{'loss': 0.1005, 'grad_norm': 9.939481735229492, 'learning_rate': 4.56e-06, 'epoch': 7.04}\n",
      "{'loss': 0.0981, 'grad_norm': 5.960977077484131, 'learning_rate': 4.541481481481482e-06, 'epoch': 7.04}\n",
      "{'loss': 0.0951, 'grad_norm': 3.1765241622924805, 'learning_rate': 4.522962962962964e-06, 'epoch': 7.04}\n",
      "{'loss': 0.0908, 'grad_norm': 4.1769843101501465, 'learning_rate': 4.504444444444444e-06, 'epoch': 7.04}\n",
      "{'loss': 0.095, 'grad_norm': 5.218709468841553, 'learning_rate': 4.485925925925926e-06, 'epoch': 7.04}\n",
      "{'loss': 0.0728, 'grad_norm': 4.104994297027588, 'learning_rate': 4.467407407407408e-06, 'epoch': 7.05}\n",
      "{'loss': 0.1239, 'grad_norm': 7.5342841148376465, 'learning_rate': 4.448888888888889e-06, 'epoch': 7.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Too many dataloader workers: 16 (max is dataset.n_shards=1). Stopping 15 dataloader workers.\n",
      "Reading metadata...: 8353it [00:02, 3199.77it/s]\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22851969301700592, 'eval_wer': 60.945624624389225, 'eval_runtime': 1341.3645, 'eval_samples_per_second': 6.227, 'eval_steps_per_second': 0.39, 'epoch': 7.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahanaf/Torch/torch2_2/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.116, 'grad_norm': 4.621915340423584, 'learning_rate': 4.430370370370371e-06, 'epoch': 7.05}\n",
      "{'loss': 0.0953, 'grad_norm': 3.883129835128784, 'learning_rate': 4.4118518518518526e-06, 'epoch': 7.05}\n",
      "{'loss': 0.0924, 'grad_norm': 4.679626941680908, 'learning_rate': 4.393333333333334e-06, 'epoch': 7.05}\n",
      "{'loss': 0.0652, 'grad_norm': 3.3765058517456055, 'learning_rate': 4.374814814814815e-06, 'epoch': 7.05}\n",
      "{'loss': 0.0613, 'grad_norm': 4.0873494148254395, 'learning_rate': 4.356296296296297e-06, 'epoch': 7.06}\n",
      "{'loss': 0.0729, 'grad_norm': 4.310512542724609, 'learning_rate': 4.337777777777778e-06, 'epoch': 7.06}\n",
      "{'loss': 0.0767, 'grad_norm': 6.309560775756836, 'learning_rate': 4.31925925925926e-06, 'epoch': 7.06}\n",
      "{'loss': 0.0919, 'grad_norm': 5.2737717628479, 'learning_rate': 4.300740740740741e-06, 'epoch': 7.06}\n",
      "{'loss': 0.0632, 'grad_norm': 5.4362335205078125, 'learning_rate': 4.282222222222222e-06, 'epoch': 7.06}\n",
      "{'loss': 0.0717, 'grad_norm': 4.676727771759033, 'learning_rate': 4.263703703703704e-06, 'epoch': 7.06}\n",
      "{'loss': 0.0558, 'grad_norm': 4.271203994750977, 'learning_rate': 4.2451851851851855e-06, 'epoch': 7.07}\n",
      "{'loss': 0.0518, 'grad_norm': 2.390882730484009, 'learning_rate': 4.226666666666667e-06, 'epoch': 7.07}\n",
      "{'loss': 0.093, 'grad_norm': 4.948744773864746, 'learning_rate': 4.208148148148149e-06, 'epoch': 7.07}\n",
      "{'loss': 0.0718, 'grad_norm': 4.804070949554443, 'learning_rate': 4.18962962962963e-06, 'epoch': 7.07}\n",
      "{'loss': 0.0869, 'grad_norm': 5.35667085647583, 'learning_rate': 4.171111111111111e-06, 'epoch': 7.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Too many dataloader workers: 16 (max is dataset.n_shards=1). Stopping 15 dataloader workers.\n",
      "Reading metadata...: 16777it [00:03, 5162.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0978, 'grad_norm': 3.308157205581665, 'learning_rate': 4.152592592592593e-06, 'epoch': 8.0}\n",
      "{'loss': 0.0951, 'grad_norm': 5.362303733825684, 'learning_rate': 4.1340740740740744e-06, 'epoch': 8.0}\n",
      "{'loss': 0.0878, 'grad_norm': 6.840925693511963, 'learning_rate': 4.115555555555556e-06, 'epoch': 8.0}\n",
      "{'loss': 0.0926, 'grad_norm': 5.695345878601074, 'learning_rate': 4.097037037037037e-06, 'epoch': 8.01}\n",
      "{'loss': 0.0884, 'grad_norm': 5.25306510925293, 'learning_rate': 4.0785185185185185e-06, 'epoch': 8.01}\n",
      "{'loss': 0.1001, 'grad_norm': 6.031040191650391, 'learning_rate': 4.060000000000001e-06, 'epoch': 8.01}\n",
      "{'loss': 0.092, 'grad_norm': 2.8535549640655518, 'learning_rate': 4.041481481481482e-06, 'epoch': 8.01}\n",
      "{'loss': 0.0784, 'grad_norm': 5.693019390106201, 'learning_rate': 4.022962962962963e-06, 'epoch': 8.01}\n",
      "{'loss': 0.0863, 'grad_norm': 5.08974027633667, 'learning_rate': 4.004444444444445e-06, 'epoch': 8.01}\n",
      "{'loss': 0.0779, 'grad_norm': 3.221926689147949, 'learning_rate': 3.985925925925927e-06, 'epoch': 8.02}\n",
      "{'loss': 0.0798, 'grad_norm': 4.513500213623047, 'learning_rate': 3.967407407407407e-06, 'epoch': 8.02}\n",
      "{'loss': 0.0869, 'grad_norm': 3.912198305130005, 'learning_rate': 3.948888888888889e-06, 'epoch': 8.02}\n",
      "{'loss': 0.0867, 'grad_norm': 5.472676753997803, 'learning_rate': 3.930370370370371e-06, 'epoch': 8.02}\n",
      "{'loss': 0.0908, 'grad_norm': 5.564949989318848, 'learning_rate': 3.911851851851852e-06, 'epoch': 8.02}\n",
      "{'loss': 0.0901, 'grad_norm': 5.940522193908691, 'learning_rate': 3.893333333333333e-06, 'epoch': 8.03}\n",
      "{'loss': 0.0838, 'grad_norm': 2.2985448837280273, 'learning_rate': 3.8748148148148155e-06, 'epoch': 8.03}\n",
      "{'loss': 0.0731, 'grad_norm': 4.442333221435547, 'learning_rate': 3.856296296296297e-06, 'epoch': 8.03}\n",
      "{'loss': 0.0786, 'grad_norm': 3.152435064315796, 'learning_rate': 3.837777777777778e-06, 'epoch': 8.03}\n",
      "{'loss': 0.0711, 'grad_norm': 3.942154884338379, 'learning_rate': 3.8192592592592596e-06, 'epoch': 8.03}\n",
      "{'loss': 0.0949, 'grad_norm': 3.8631718158721924, 'learning_rate': 3.8007407407407408e-06, 'epoch': 8.03}\n",
      "{'loss': 0.0913, 'grad_norm': 6.577359676361084, 'learning_rate': 3.782222222222223e-06, 'epoch': 8.04}\n",
      "{'loss': 0.0835, 'grad_norm': 3.0706889629364014, 'learning_rate': 3.763703703703704e-06, 'epoch': 8.04}\n",
      "{'loss': 0.0829, 'grad_norm': 3.492833137512207, 'learning_rate': 3.7451851851851856e-06, 'epoch': 8.04}\n",
      "{'loss': 0.0799, 'grad_norm': 4.844571113586426, 'learning_rate': 3.726666666666667e-06, 'epoch': 8.04}\n",
      "{'loss': 0.0831, 'grad_norm': 3.7559661865234375, 'learning_rate': 3.7081481481481485e-06, 'epoch': 8.04}\n",
      "{'loss': 0.0622, 'grad_norm': 3.305662155151367, 'learning_rate': 3.6896296296296297e-06, 'epoch': 8.05}\n",
      "{'loss': 0.1158, 'grad_norm': 6.310856819152832, 'learning_rate': 3.6711111111111113e-06, 'epoch': 8.05}\n",
      "{'loss': 0.1013, 'grad_norm': 4.53671932220459, 'learning_rate': 3.652592592592593e-06, 'epoch': 8.05}\n",
      "{'loss': 0.0824, 'grad_norm': 3.2460036277770996, 'learning_rate': 3.634074074074074e-06, 'epoch': 8.05}\n",
      "{'loss': 0.0818, 'grad_norm': 2.5626471042633057, 'learning_rate': 3.615555555555556e-06, 'epoch': 8.05}\n",
      "{'loss': 0.0559, 'grad_norm': 2.861342191696167, 'learning_rate': 3.5970370370370374e-06, 'epoch': 8.05}\n",
      "{'loss': 0.0522, 'grad_norm': 3.732560396194458, 'learning_rate': 3.578518518518519e-06, 'epoch': 8.06}\n",
      "{'loss': 0.064, 'grad_norm': 5.884850025177002, 'learning_rate': 3.5600000000000002e-06, 'epoch': 8.06}\n",
      "{'loss': 0.0666, 'grad_norm': 5.479475975036621, 'learning_rate': 3.541481481481482e-06, 'epoch': 8.06}\n",
      "{'loss': 0.0797, 'grad_norm': 4.553125858306885, 'learning_rate': 3.522962962962963e-06, 'epoch': 8.06}\n",
      "{'loss': 0.0544, 'grad_norm': 3.292886734008789, 'learning_rate': 3.5044444444444447e-06, 'epoch': 8.06}\n",
      "{'loss': 0.062, 'grad_norm': 3.459355115890503, 'learning_rate': 3.485925925925926e-06, 'epoch': 8.06}\n",
      "{'loss': 0.0468, 'grad_norm': 3.7059483528137207, 'learning_rate': 3.4674074074074075e-06, 'epoch': 8.07}\n",
      "{'loss': 0.0455, 'grad_norm': 5.237095832824707, 'learning_rate': 3.4488888888888896e-06, 'epoch': 8.07}\n",
      "{'loss': 0.0815, 'grad_norm': 6.359719276428223, 'learning_rate': 3.4303703703703708e-06, 'epoch': 8.07}\n",
      "{'loss': 0.0609, 'grad_norm': 3.4263758659362793, 'learning_rate': 3.4118518518518524e-06, 'epoch': 8.07}\n",
      "{'loss': 0.0786, 'grad_norm': 5.5973968505859375, 'learning_rate': 3.3933333333333336e-06, 'epoch': 8.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Too many dataloader workers: 16 (max is dataset.n_shards=1). Stopping 15 dataloader workers.\n",
      "Reading metadata...: 16777it [00:03, 5512.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0885, 'grad_norm': 5.780967712402344, 'learning_rate': 3.3748148148148152e-06, 'epoch': 9.0}\n",
      "{'loss': 0.0851, 'grad_norm': 6.253446102142334, 'learning_rate': 3.3562962962962964e-06, 'epoch': 9.0}\n",
      "{'loss': 0.0764, 'grad_norm': 5.086822509765625, 'learning_rate': 3.337777777777778e-06, 'epoch': 9.0}\n",
      "{'loss': 0.0814, 'grad_norm': 4.773820877075195, 'learning_rate': 3.3192592592592593e-06, 'epoch': 9.01}\n",
      "{'loss': 0.0762, 'grad_norm': 3.6918210983276367, 'learning_rate': 3.300740740740741e-06, 'epoch': 9.01}\n",
      "{'loss': 0.093, 'grad_norm': 7.059060573577881, 'learning_rate': 3.282222222222223e-06, 'epoch': 9.01}\n",
      "{'loss': 0.0774, 'grad_norm': 4.185916423797607, 'learning_rate': 3.263703703703704e-06, 'epoch': 9.01}\n",
      "{'loss': 0.0682, 'grad_norm': 5.49619722366333, 'learning_rate': 3.2451851851851858e-06, 'epoch': 9.01}\n",
      "{'loss': 0.0768, 'grad_norm': 4.953460216522217, 'learning_rate': 3.226666666666667e-06, 'epoch': 9.01}\n",
      "{'loss': 0.0657, 'grad_norm': 3.6533865928649902, 'learning_rate': 3.2081481481481486e-06, 'epoch': 9.02}\n",
      "{'loss': 0.0712, 'grad_norm': 4.294821262359619, 'learning_rate': 3.18962962962963e-06, 'epoch': 9.02}\n",
      "{'loss': 0.0779, 'grad_norm': 5.451376914978027, 'learning_rate': 3.1711111111111114e-06, 'epoch': 9.02}\n",
      "{'loss': 0.0793, 'grad_norm': 7.810362339019775, 'learning_rate': 3.1525925925925926e-06, 'epoch': 9.02}\n",
      "{'loss': 0.0766, 'grad_norm': 4.626252174377441, 'learning_rate': 3.1340740740740743e-06, 'epoch': 9.02}\n",
      "{'loss': 0.0841, 'grad_norm': 9.278539657592773, 'learning_rate': 3.1155555555555555e-06, 'epoch': 9.03}\n",
      "{'loss': 0.0693, 'grad_norm': 4.8192644119262695, 'learning_rate': 3.097037037037037e-06, 'epoch': 9.03}\n",
      "{'loss': 0.0622, 'grad_norm': 3.41408371925354, 'learning_rate': 3.078518518518519e-06, 'epoch': 9.03}\n",
      "{'loss': 0.0698, 'grad_norm': 4.392715930938721, 'learning_rate': 3.0600000000000003e-06, 'epoch': 9.03}\n",
      "{'loss': 0.0648, 'grad_norm': 5.860809803009033, 'learning_rate': 3.041481481481482e-06, 'epoch': 9.03}\n",
      "{'loss': 0.0843, 'grad_norm': 6.74425745010376, 'learning_rate': 3.022962962962963e-06, 'epoch': 9.03}\n",
      "{'loss': 0.0782, 'grad_norm': 4.354415416717529, 'learning_rate': 3.004444444444445e-06, 'epoch': 9.04}\n",
      "{'loss': 0.0732, 'grad_norm': 3.9723711013793945, 'learning_rate': 2.985925925925926e-06, 'epoch': 9.04}\n",
      "{'loss': 0.0727, 'grad_norm': 3.458711624145508, 'learning_rate': 2.9674074074074076e-06, 'epoch': 9.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Too many dataloader workers: 16 (max is dataset.n_shards=1). Stopping 15 dataloader workers.\n",
      "Reading metadata...: 8353it [00:02, 3603.32it/s]\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24130722880363464, 'eval_wer': 60.33288913276371, 'eval_runtime': 1345.3545, 'eval_samples_per_second': 6.209, 'eval_steps_per_second': 0.389, 'epoch': 9.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahanaf/Torch/torch2_2/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0719, 'grad_norm': 5.174563884735107, 'learning_rate': 2.948888888888889e-06, 'epoch': 9.04}\n",
      "{'loss': 0.0755, 'grad_norm': 6.608218669891357, 'learning_rate': 2.9303703703703705e-06, 'epoch': 9.04}\n",
      "{'loss': 0.0523, 'grad_norm': 5.388758182525635, 'learning_rate': 2.9118518518518517e-06, 'epoch': 9.05}\n",
      "{'loss': 0.1065, 'grad_norm': 5.887277126312256, 'learning_rate': 2.8933333333333337e-06, 'epoch': 9.05}\n",
      "{'loss': 0.0886, 'grad_norm': 3.7672016620635986, 'learning_rate': 2.8748148148148154e-06, 'epoch': 9.05}\n",
      "{'loss': 0.0771, 'grad_norm': 7.151106834411621, 'learning_rate': 2.8562962962962966e-06, 'epoch': 9.05}\n",
      "{'loss': 0.0689, 'grad_norm': 2.7750704288482666, 'learning_rate': 2.837777777777778e-06, 'epoch': 9.05}\n",
      "{'loss': 0.048, 'grad_norm': 2.4282751083374023, 'learning_rate': 2.8192592592592594e-06, 'epoch': 9.05}\n",
      "{'loss': 0.0455, 'grad_norm': 3.2004592418670654, 'learning_rate': 2.800740740740741e-06, 'epoch': 9.06}\n",
      "{'loss': 0.0563, 'grad_norm': 4.610203742980957, 'learning_rate': 2.7822222222222222e-06, 'epoch': 9.06}\n",
      "{'loss': 0.0572, 'grad_norm': 3.892888307571411, 'learning_rate': 2.763703703703704e-06, 'epoch': 9.06}\n",
      "{'loss': 0.0705, 'grad_norm': 4.278266906738281, 'learning_rate': 2.745185185185185e-06, 'epoch': 9.06}\n",
      "{'loss': 0.0467, 'grad_norm': 2.8630285263061523, 'learning_rate': 2.726666666666667e-06, 'epoch': 9.06}\n",
      "{'loss': 0.0551, 'grad_norm': 3.280360460281372, 'learning_rate': 2.7081481481481487e-06, 'epoch': 9.06}\n",
      "{'loss': 0.0407, 'grad_norm': 3.269078254699707, 'learning_rate': 2.68962962962963e-06, 'epoch': 9.07}\n",
      "{'loss': 0.0386, 'grad_norm': 3.1244828701019287, 'learning_rate': 2.6711111111111116e-06, 'epoch': 9.07}\n",
      "{'loss': 0.0734, 'grad_norm': 3.7353925704956055, 'learning_rate': 2.6525925925925928e-06, 'epoch': 9.07}\n",
      "{'loss': 0.0526, 'grad_norm': 4.020904541015625, 'learning_rate': 2.6340740740740744e-06, 'epoch': 9.07}\n",
      "{'loss': 0.0714, 'grad_norm': 6.234874248504639, 'learning_rate': 2.6155555555555556e-06, 'epoch': 9.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Too many dataloader workers: 16 (max is dataset.n_shards=1). Stopping 15 dataloader workers.\n",
      "Reading metadata...: 16777it [00:03, 5135.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0796, 'grad_norm': 4.788090229034424, 'learning_rate': 2.5970370370370372e-06, 'epoch': 10.0}\n",
      "{'loss': 0.0763, 'grad_norm': 6.6651930809021, 'learning_rate': 2.5785185185185184e-06, 'epoch': 10.0}\n",
      "{'loss': 0.0657, 'grad_norm': 3.694990634918213, 'learning_rate': 2.56e-06, 'epoch': 10.0}\n",
      "{'loss': 0.0733, 'grad_norm': 4.8404035568237305, 'learning_rate': 2.5414814814814813e-06, 'epoch': 10.01}\n",
      "{'loss': 0.0668, 'grad_norm': 4.640250205993652, 'learning_rate': 2.5229629629629633e-06, 'epoch': 10.01}\n",
      "{'loss': 0.0846, 'grad_norm': 4.365676403045654, 'learning_rate': 2.504444444444445e-06, 'epoch': 10.01}\n",
      "{'loss': 0.0683, 'grad_norm': 4.276456356048584, 'learning_rate': 2.485925925925926e-06, 'epoch': 10.01}\n",
      "{'loss': 0.0611, 'grad_norm': 5.738658905029297, 'learning_rate': 2.4674074074074073e-06, 'epoch': 10.01}\n",
      "{'loss': 0.069, 'grad_norm': 5.826195240020752, 'learning_rate': 2.448888888888889e-06, 'epoch': 10.02}\n",
      "{'loss': 0.0555, 'grad_norm': 3.4955544471740723, 'learning_rate': 2.4303703703703706e-06, 'epoch': 10.02}\n",
      "{'loss': 0.0665, 'grad_norm': 5.379809856414795, 'learning_rate': 2.4118518518518522e-06, 'epoch': 10.02}\n",
      "{'loss': 0.0717, 'grad_norm': 6.999547481536865, 'learning_rate': 2.3933333333333334e-06, 'epoch': 10.02}\n",
      "{'loss': 0.0686, 'grad_norm': 6.250651836395264, 'learning_rate': 2.374814814814815e-06, 'epoch': 10.02}\n",
      "{'loss': 0.0674, 'grad_norm': 3.8880271911621094, 'learning_rate': 2.3562962962962967e-06, 'epoch': 10.02}\n",
      "{'loss': 0.0748, 'grad_norm': 3.6309165954589844, 'learning_rate': 2.337777777777778e-06, 'epoch': 10.03}\n",
      "{'loss': 0.0608, 'grad_norm': 3.871166467666626, 'learning_rate': 2.3192592592592595e-06, 'epoch': 10.03}\n",
      "{'loss': 0.0542, 'grad_norm': 3.1200921535491943, 'learning_rate': 2.3007407407407407e-06, 'epoch': 10.03}\n",
      "{'loss': 0.0626, 'grad_norm': 3.6512317657470703, 'learning_rate': 2.2822222222222223e-06, 'epoch': 10.03}\n",
      "{'loss': 0.0575, 'grad_norm': 3.5164453983306885, 'learning_rate': 2.263703703703704e-06, 'epoch': 10.03}\n",
      "{'loss': 0.0758, 'grad_norm': 4.068480968475342, 'learning_rate': 2.245185185185185e-06, 'epoch': 10.03}\n",
      "{'loss': 0.0748, 'grad_norm': 7.424282550811768, 'learning_rate': 2.226666666666667e-06, 'epoch': 10.04}\n",
      "{'loss': 0.0604, 'grad_norm': 3.3151748180389404, 'learning_rate': 2.2081481481481484e-06, 'epoch': 10.04}\n",
      "{'loss': 0.0646, 'grad_norm': 2.853179454803467, 'learning_rate': 2.18962962962963e-06, 'epoch': 10.04}\n",
      "{'loss': 0.0655, 'grad_norm': 4.709963798522949, 'learning_rate': 2.1711111111111113e-06, 'epoch': 10.04}\n"
     ]
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kwargs = {\n",
    "#     \"dataset_tags\": \"mozilla-foundation/common_voice_11_0\",\n",
    "#     \"dataset\": \"Common Voice 11.0\",  # a 'pretty' name for the training dataset\n",
    "#     \"dataset_args\": \"config: bn, split: test\",\n",
    "#     \"language\": \"bn\",\n",
    "#     \"model_name\": \"Whisper Tiny BN - ahanaf019\",  # a 'pretty' name for your model\n",
    "#     \"finetuned_from\": \"openai/whisper-tiny\",\n",
    "#     \"tasks\": \"automatic-speech-recognition\",\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.push_to_hub(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('active.all.allocated', 284789737),\n",
       "             ('active.all.current', 503),\n",
       "             ('active.all.freed', 284789234),\n",
       "             ('active.all.peak', 775),\n",
       "             ('active.large_pool.allocated', 31463846),\n",
       "             ('active.large_pool.current', 57),\n",
       "             ('active.large_pool.freed', 31463789),\n",
       "             ('active.large_pool.peak', 106),\n",
       "             ('active.small_pool.allocated', 253325891),\n",
       "             ('active.small_pool.current', 446),\n",
       "             ('active.small_pool.freed', 253325445),\n",
       "             ('active.small_pool.peak', 698),\n",
       "             ('active_bytes.all.allocated', 302894913586176),\n",
       "             ('active_bytes.all.current', 465560064),\n",
       "             ('active_bytes.all.freed', 302894448026112),\n",
       "             ('active_bytes.all.peak', 4381111808),\n",
       "             ('active_bytes.large_pool.allocated', 256030036684288),\n",
       "             ('active_bytes.large_pool.current', 376891904),\n",
       "             ('active_bytes.large_pool.freed', 256029659792384),\n",
       "             ('active_bytes.large_pool.peak', 4291013120),\n",
       "             ('active_bytes.small_pool.allocated', 46864876901888),\n",
       "             ('active_bytes.small_pool.current', 88668160),\n",
       "             ('active_bytes.small_pool.freed', 46864788233728),\n",
       "             ('active_bytes.small_pool.peak', 147670528),\n",
       "             ('allocated_bytes.all.allocated', 302894913586176),\n",
       "             ('allocated_bytes.all.current', 465560064),\n",
       "             ('allocated_bytes.all.freed', 302894448026112),\n",
       "             ('allocated_bytes.all.peak', 4381111808),\n",
       "             ('allocated_bytes.large_pool.allocated', 256030036684288),\n",
       "             ('allocated_bytes.large_pool.current', 376891904),\n",
       "             ('allocated_bytes.large_pool.freed', 256029659792384),\n",
       "             ('allocated_bytes.large_pool.peak', 4291013120),\n",
       "             ('allocated_bytes.small_pool.allocated', 46864876901888),\n",
       "             ('allocated_bytes.small_pool.current', 88668160),\n",
       "             ('allocated_bytes.small_pool.freed', 46864788233728),\n",
       "             ('allocated_bytes.small_pool.peak', 147670528),\n",
       "             ('allocation.all.allocated', 284789737),\n",
       "             ('allocation.all.current', 503),\n",
       "             ('allocation.all.freed', 284789234),\n",
       "             ('allocation.all.peak', 775),\n",
       "             ('allocation.large_pool.allocated', 31463846),\n",
       "             ('allocation.large_pool.current', 57),\n",
       "             ('allocation.large_pool.freed', 31463789),\n",
       "             ('allocation.large_pool.peak', 106),\n",
       "             ('allocation.small_pool.allocated', 253325891),\n",
       "             ('allocation.small_pool.current', 446),\n",
       "             ('allocation.small_pool.freed', 253325445),\n",
       "             ('allocation.small_pool.peak', 698),\n",
       "             ('inactive_split.all.allocated', 0),\n",
       "             ('inactive_split.all.current', 0),\n",
       "             ('inactive_split.all.freed', 0),\n",
       "             ('inactive_split.all.peak', 0),\n",
       "             ('inactive_split.large_pool.allocated', 0),\n",
       "             ('inactive_split.large_pool.current', 0),\n",
       "             ('inactive_split.large_pool.freed', 0),\n",
       "             ('inactive_split.large_pool.peak', 0),\n",
       "             ('inactive_split.small_pool.allocated', 0),\n",
       "             ('inactive_split.small_pool.current', 0),\n",
       "             ('inactive_split.small_pool.freed', 0),\n",
       "             ('inactive_split.small_pool.peak', 0),\n",
       "             ('inactive_split_bytes.all.allocated', 0),\n",
       "             ('inactive_split_bytes.all.current', 0),\n",
       "             ('inactive_split_bytes.all.freed', 0),\n",
       "             ('inactive_split_bytes.all.peak', 0),\n",
       "             ('inactive_split_bytes.large_pool.allocated', 0),\n",
       "             ('inactive_split_bytes.large_pool.current', 0),\n",
       "             ('inactive_split_bytes.large_pool.freed', 0),\n",
       "             ('inactive_split_bytes.large_pool.peak', 0),\n",
       "             ('inactive_split_bytes.small_pool.allocated', 0),\n",
       "             ('inactive_split_bytes.small_pool.current', 0),\n",
       "             ('inactive_split_bytes.small_pool.freed', 0),\n",
       "             ('inactive_split_bytes.small_pool.peak', 0),\n",
       "             ('max_split_size', -1),\n",
       "             ('num_alloc_retries', 0),\n",
       "             ('num_ooms', 0),\n",
       "             ('oversize_allocations.allocated', 0),\n",
       "             ('oversize_allocations.current', 0),\n",
       "             ('oversize_allocations.freed', 0),\n",
       "             ('oversize_allocations.peak', 0),\n",
       "             ('oversize_segments.allocated', 0),\n",
       "             ('oversize_segments.current', 0),\n",
       "             ('oversize_segments.freed', 0),\n",
       "             ('oversize_segments.peak', 0),\n",
       "             ('requested_bytes.all.allocated', 302861635856261),\n",
       "             ('requested_bytes.all.current', 465559048),\n",
       "             ('requested_bytes.all.freed', 302861170297213),\n",
       "             ('requested_bytes.all.peak', 4381105116),\n",
       "             ('requested_bytes.large_pool.allocated', 256029495978140),\n",
       "             ('requested_bytes.large_pool.current', 376891904),\n",
       "             ('requested_bytes.large_pool.freed', 256029119086236),\n",
       "             ('requested_bytes.large_pool.peak', 4291011776),\n",
       "             ('requested_bytes.small_pool.allocated', 46832139878121),\n",
       "             ('requested_bytes.small_pool.current', 88667144),\n",
       "             ('requested_bytes.small_pool.freed', 46832051210977),\n",
       "             ('requested_bytes.small_pool.peak', 147666968),\n",
       "             ('reserved_bytes.all.allocated', 4515168256),\n",
       "             ('reserved_bytes.all.current', 4515168256),\n",
       "             ('reserved_bytes.all.freed', 0),\n",
       "             ('reserved_bytes.all.peak', 4515168256),\n",
       "             ('reserved_bytes.large_pool.allocated', 4362076160),\n",
       "             ('reserved_bytes.large_pool.current', 4362076160),\n",
       "             ('reserved_bytes.large_pool.freed', 0),\n",
       "             ('reserved_bytes.large_pool.peak', 4362076160),\n",
       "             ('reserved_bytes.small_pool.allocated', 153092096),\n",
       "             ('reserved_bytes.small_pool.current', 153092096),\n",
       "             ('reserved_bytes.small_pool.freed', 0),\n",
       "             ('reserved_bytes.small_pool.peak', 153092096),\n",
       "             ('segment.all.allocated', 0),\n",
       "             ('segment.all.current', 0),\n",
       "             ('segment.all.freed', 0),\n",
       "             ('segment.all.peak', 0),\n",
       "             ('segment.large_pool.allocated', 0),\n",
       "             ('segment.large_pool.current', 0),\n",
       "             ('segment.large_pool.freed', 0),\n",
       "             ('segment.large_pool.peak', 0),\n",
       "             ('segment.small_pool.allocated', 0),\n",
       "             ('segment.small_pool.current', 0),\n",
       "             ('segment.small_pool.freed', 0),\n",
       "             ('segment.small_pool.peak', 0)])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
